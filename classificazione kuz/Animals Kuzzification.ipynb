{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Animals in 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "import keras.callbacks as callbacks\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting current working directory and dataset location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "img_path = os.path.join(current_path, 'raw-img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dataset and defining train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.keras.utils.image_dataset_from_directory(\n",
    "    img_path,\n",
    "    image_size=(224,224),\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=21\n",
    "    )\n",
    "\n",
    "val = tf.keras.utils.image_dataset_from_directory(\n",
    "    img_path,\n",
    "    image_size=(224,224),\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=21\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling image in order to check if the data is loaded correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the labels are in italian and are traslated in english in the following code: <br>\n",
    "\"cane\" = \"dog\", \"cavallo\" = \"horse\", \"elefante\" = \"elephant\", \"farfalla\" = \"butterfly\", \"gallina\" = \"hen\", \\\n",
    "\"gatto\" = \"cat\", \"mucca\" = \"cow\", \"pecora\" = \"sheep\", \"ragno\" = \"spider\", \"scoiattolo\" = \"squirrel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = random.randint(0,32)\n",
    "sample = train.take(1).map(lambda x, y: (x[0],y[0])).as_numpy_iterator()\n",
    "for i,j in sample:\n",
    "    plt.imshow(i)\n",
    "    # plt.title()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the data for performance and better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image,label):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image,label\n",
    "\n",
    "train = train.map(process)\n",
    "val = val.map(process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    zoom_range=[0.8, 1.2],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "# 1. ModelCheckpoint\n",
    "# 2. EarlyStopping\n",
    "# 3. ReduceLROnPlateau\n",
    "# 4. TensorBoard\n",
    "\n",
    "callbacks_list = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(current_path, 'models/kuz_model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    ),\n",
    "\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.0001,\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "    ),\n",
    "\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=20\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list2 = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(current_path, 'models/kuz2_model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    ),\n",
    "        \n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.0001,\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "    ),\n",
    "\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kuz_model = Sequential(\n",
    "    [\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(10, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "kuz_model.summary()\n",
    "\n",
    "kuz_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    # loss=categorical_crossentropy,\n",
    "    loss=SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kuz_model2 = Sequential(\n",
    "    [\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        Flatten(),\n",
    "        Dense(2048, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(10, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "kuz_model2.summary()\n",
    "\n",
    "kuz_model2.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    # loss=categorical_crossentropy,\n",
    "    loss=SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model = Sequential(\n",
    "    [\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        \n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        \n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        \n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        \n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        \n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        \n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        \n",
    "        Dense(10, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "vgg19_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = kuz_model.fit(\n",
    "    train,\n",
    "    validation_data=val,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = kuz_model2.fit(\n",
    "    train,\n",
    "    validation_data=val,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks_list2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizing the models performance over the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the training and validation accuracy\n",
    "plt.plot(history1.history['accuracy'])\n",
    "plt.plot(history1.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#plotting the training and validation loss\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the training and validation accuracy\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#plotting the training and validation loss\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLTensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
